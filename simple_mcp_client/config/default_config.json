{
  "llm": {
    "provider": "ollama",
    "model": "llama3",
    "api_url": "http://localhost:11434/api",
    "api_key": null,
    "other_params": {
      "temperature": 0.7,
      "max_tokens": 4096
    }
  },
  "mcpServers": {
    "k8s": {
      "type": "sse",
      "url": "http://192.168.182.128:8000/sse",
      "command": null,
      "args": [],
      "env": {}
    }
  },
  "default_server": "k8s"
}
